<launch>
	<group ns="vision">
		<!-- Good for testing will push the web camera into a ros topic and return embedding as well as a image with bounding boxes!!! -->
		<node name="face_recog_lib_node" pkg="face_recognition" type="face_recognition_node.py" output="screen">
			<param name="train_dir" value="/home/takeshi/data_sets/facerecognition/"/>
			<!-- Causes the node to continously recognize people from a message good for debugging! -->
			<param name="stream" value="True"/>
			<param name="debug" value="False"/>
			<remap from="/usb_cam/image_raw" to="/vision/usb_cam/image_raw" />
		</node>

		<node name="usb_cam" pkg="usb_cam" type="usb_cam_node" output="screen">
			<param name="video_device" value="/dev/video0"/>
			<param name="image_width" value="640"/>
			<param name="image_height" value="480"/>
			<param name="pixel_format" value="yuyv"/>
			<param name="camera_frame_id" value="usb_cam"/>
			<param name="io_method" value="mmap"/>
		</node>

		 <node name="openpose_node" pkg="openpose" type="open_pose_node" output="screen">
      <param name="debug_mode" value="false"/>
      <param name="file_links_config" value="$(find openpose)/OpenPoseConfig.xml"/>
      <param name="model_folder" value="$(env OPENPOSE_HOME)/models/"/>
      <param name="net_resolution" value="640x480"/>
      <remap from="/vision/openpose/enable_estimate_pose" to="/vision/skeleton_finder/enable_tracking"/>
      <remap from="/vision/openpose/skeleton_recog" to="/vision/skeleton_finder/skeleton_recog"/>
    </node>

    <node name="gesture_recog_skeleton" pkg="gesture_recog_skeleton" type="gesture_recog_node" output="screen">
      <param name="gesture_method" value="1"/>
      <!-- This params are to waving detect -->
      <param name="num_frames" value="10"/>
      <param name="thr_waving_motion" value="0.3"/>
      <param name="thr_to_person" value="0.3"/>
      <param name="time_elapsed_remove" value="10.0"/>
    </node>

</group>
</launch>
	